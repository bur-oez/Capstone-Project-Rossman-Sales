{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5037f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "import datetime\n",
    "\n",
    "#plotting\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style(\n",
    "    style='darkgrid', \n",
    "    rc={'axes.facecolor': '.9', 'grid.color': '.8'}\n",
    ")\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "#time series analysis and modelling\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from statsmodels.tsa.stattools import adfuller,kpss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555f923a",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7a594c",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b84fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "df_store = pd.read_csv('data/store.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467361c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800da230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to rename columns in lower case\n",
    "def lower_case(dataframe):\n",
    "    cols = dataframe.columns.tolist()\n",
    "    cols = [col.lower() for col in cols]\n",
    "    dataframe.columns = cols\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c04e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_case(df_train);\n",
    "lower_case(df_store);\n",
    "lower_case(df_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506c5cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to change date into datetime\n",
    "def to_datetime(dataframe):\n",
    "    dataframe.assign(\n",
    "        timestamp = lambda x: pd.to_datetime(x['date']),\n",
    "        year = lambda x: x['timestamp'].dt.year,\n",
    "        month = lambda x: x['timestamp'].dt.month,\n",
    "        day = lambda x: x['timestamp'].dt.day,\n",
    "        dayofyear = lambda x: x['timestamp'].dt.dayofyear)\n",
    "    return dataframe\n",
    "# does not work :( "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3c4587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train = to_datetime(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8bf42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing date into datetime object, inserting year, month, day and dayofyear columns\n",
    "df_train = df_train.assign(\n",
    "            timestamp = lambda x: pd.to_datetime(x['date']),\n",
    "            year = lambda x: x['timestamp'].dt.year,\n",
    "            month = lambda x: x['timestamp'].dt.month,\n",
    "            day = lambda x: x['timestamp'].dt.day,\n",
    "            dayofyear = lambda x: x['timestamp'].dt.dayofyear)\n",
    "df_train.drop(\"date\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0bdf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57afdf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_store.shape)\n",
    "df_store.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda63cc5",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fa1e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732fdfba",
   "metadata": {},
   "source": [
    "### Closed stores and zero sales stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223ca44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# closed stores\n",
    "df_train[(df_train['open'] == 0) & (df_train['sales'] == 0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1fcd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[(df_train['open'] != 0) & (df_train['sales'] == 0)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af152b4",
   "metadata": {},
   "source": [
    "There are 172817 stores, which were closed and had no sales. In addition to 54 open stores, which had no sales at that day.\n",
    "\n",
    "We cannot make any predictions for stores, which were closed, and stores which were open, but had no sales, might have had external influences, such as remodeling.\n",
    "\n",
    "To avoid any bias, we should drop these datapoints with 0 sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3e2069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[(df_train[\"open\"] != 0) & (df_train['sales'] != 0)]\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac7c86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['stateholiday'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e496558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.stateholiday.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55628420",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['stateholiday'].replace({0:'0'}, inplace=True)\n",
    "round(df_train.describe().T,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be9ccfd",
   "metadata": {},
   "source": [
    "### Cleaning NaN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a08303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d88c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store[pd.isnull(df_store.competitiondistance)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f81b256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NaN with a median value\n",
    "df_store['competitiondistance'].fillna(df_store['competitiondistance'].median(), inplace = True)\n",
    "df_store['competitiondistance'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01123898",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_store[pd.isnull(df_store.competitionopensinceyear)]\n",
    "tmp[tmp.competitiondistance != 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd140d8",
   "metadata": {},
   "source": [
    "Here these stores have a competition in their vicinity ('competitiondistance' =/= 0), but there is no information about the year this competition has been open. This value needs to be imputed in a meaningful way. Or just filled with '0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf864262",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_store[pd.isnull(df_store.promo2sinceweek)]\n",
    "tmp[tmp.promo2 != 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86760211",
   "metadata": {},
   "source": [
    "There are no stores with information about 'promo2sinceweek' which have 'NaN' in promo2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f20cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NA's by 0\n",
    "df_store.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e541d35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_store.isnull().sum())\n",
    "print('------------------------')\n",
    "print(df_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce782d2",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b0b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_store and df_train\n",
    "df = df_train.merge(df_store, how='left', left_on=df_train.store, right_on=df_store.store)\n",
    "df.drop(['key_0', 'store_y'], axis=1, inplace=True)\n",
    "df = df.rename(columns={'store_x':'store'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4bc126",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('storetype')['sales'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532d1b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('storetype')['customers', 'sales'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2368794f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sales trends\n",
    "#sns.factorplot(data = df, x = 'month', y = \"sales\", \n",
    "#               col = 'storetype',\n",
    "#               palette = 'plasma',\n",
    "#               hue = 'storetype',\n",
    "#               row = 'promo', \n",
    "#               ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a201a32",
   "metadata": {},
   "source": [
    "Storetype B has the highest sales numbers, with the largest variance. All storetypes show increased sales numbers towards christmas. \n",
    "\n",
    "Stores which have run a promo, show higher sales. But storetypes a,c and d show a dip towards easter, if they have run a promo, which is not the case for stores without a promo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b206400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customers trends\n",
    "#sns.factorplot(data = df, x = 'month', y = \"customers\", \n",
    "#               col = 'storetype',\n",
    "#               palette = 'plasma',\n",
    "#               hue = 'storetype',\n",
    "#               row = 'promo',\n",
    "#               ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4085f456",
   "metadata": {},
   "source": [
    "Storetype B has the highest number of customers, with the largest variance. All storetypes show an increase of customers towards christmas. This trend is higher, if they have run a promo.\n",
    "\n",
    "Same effect of a dip for storetypes a,c and d in customers towards easter can be also be seen here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042e1b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sale per customer trends\n",
    "df['salepercustomer'] = df['sales']/df['customers']\n",
    "#sns.factorplot(data = df, x = 'month', y = \"salepercustomer\", \n",
    "#               col = 'storetype',\n",
    "#               palette = 'plasma',\n",
    "#               hue = 'storetype',\n",
    "#               row = 'promo', \n",
    "#               ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcdf2e7",
   "metadata": {},
   "source": [
    "Sales per customer:\n",
    "storetype b seems to be where customers only buy small items in low numbers (possible trainstation location?)\n",
    "storetype d customers buy the largest quantity\n",
    "a und c are very similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b36cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekday trends\n",
    "#sns.factorplot(data = df, x = 'dayofweek', y = \"sales\", \n",
    "#               col = 'storetype',\n",
    "#               palette = 'plasma',\n",
    "#               hue = 'storetype',\n",
    "#               row = 'promo',\n",
    "#               ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eca2b27",
   "metadata": {},
   "source": [
    "Similar trends regarding sales numbers and customers.\n",
    "Highest number of sales and customers on mondays, if a promo was run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458096d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekday customer trends\n",
    "#sns.factorplot(data = df, x = 'dayofweek', y = \"customers\", \n",
    "#               col = 'storetype',\n",
    "#               palette = 'plasma',\n",
    "#               hue = 'storetype',\n",
    "#               row = 'promo',\n",
    "#               ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d3cd88",
   "metadata": {},
   "source": [
    "Promos are run only during the work-week, no promo on saturday/sunday.\n",
    "\n",
    "Storetype b also open on sundays -> trainstation, fo sho\n",
    "storetyp a lower number of customers on saturday, c and d increased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b05a732",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "- Promos are run only during the work-week, no promo on saturday/sunday\\n\",\n",
    "- Storetype B has the highest number of customers, with the largest variance\\n\",\n",
    "- Storetype B has the highest sales numbers, with the largest variance\\n\",\n",
    "- All storetypes show increased sales numbers towards christmas\\n\",\n",
    "- Stores which have run a promo, show higher sales. But storetypes a, c and d show a dip towards easter, if they have run a promo, which is not the case for stores without a promo.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f049eb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().round(2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c444f5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CompetitionDistance Vs Sales\n",
    "df.plot(kind='scatter',x='competitiondistance',y='sales', figsize=(15,4))\n",
    "df.plot(kind='box', y='competitiondistance', figsize=(15,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd2bcea",
   "metadata": {},
   "source": [
    "75% of all stores have their nearest competitor at under 7km distance, while 50% of all stores have their nearest competitor at 2.3km."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3b577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data= df, x= 'storetype', y= 'competitiondistance', palette = 'plasma_r', order=[\"a\", \"b\", \"c\", \"d\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c25ae9",
   "metadata": {},
   "source": [
    "Storetype B has the nearest competitors, while storetyp D has the largest range and the largest mean distance. The farthest away competitors belong to Storetype A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e850ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df.groupby(df.storetype).sum()\n",
    "sns.barplot(temp_df.index, temp_df.sales, palette='Blues');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea44a0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting sales per storetype, based on promo1 or promo2\n",
    "#g = sns.FacetGrid(data = df,\n",
    "#                  col = 'promo',\n",
    "#                  row = 'promo2',\n",
    "#                  palette = 'plasma',\n",
    "#                  #hue = 'assortment',\n",
    "#                 )\n",
    "#g.map_dataframe(sns.barplot, \"storetype\", \"sales\", order=[\"a\",\"b\",\"c\",\"d\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe17ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting counts per storetype, based on promo1 or promo2\n",
    "#g = sns.FacetGrid(data = df, \n",
    "#               col = 'promo',\n",
    "#                  row = 'promo2',\n",
    "#               palette = 'plasma',\n",
    "               #hue = 'assortment',\n",
    "#               )\n",
    "#g.map_dataframe(sns.countplot, \"storetype\", order=[\"a\",\"b\",\"c\",\"d\"])\n",
    "#g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134b7e6b",
   "metadata": {},
   "source": [
    "### Datatype and Encoding of Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abe65a2",
   "metadata": {},
   "source": [
    "# Time Series Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded3a374",
   "metadata": {},
   "source": [
    "Plotting the seasonal decomposition of the sales per date. For this, the data for each day will be summed up and grouped by.\n",
    "\n",
    "Afterwards, the model will decompose the sale values in an additive manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349761e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = df.groupby(df['timestamp']).sum()\n",
    "season_decomp = seasonal_decompose(tmp_df['sales'], model='additive', freq=52)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(18,8))\n",
    "ax1.plot(season_decomp.trend)\n",
    "ax1.axhline(y = tmp_df['sales'].mean(), color = 'r', linestyle = '-', label='Sales Mean')\n",
    "ax1.set_title(\"Trend\")\n",
    "ax2.plot(season_decomp.resid)\n",
    "ax2.set_title(\"Residuals\")\n",
    "ax1.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483b21ef",
   "metadata": {},
   "source": [
    "The beginning of 2014 and 2015 show higher than average sales numbers. Especially the peak at the beginning of 2014 is very high.\n",
    "\n",
    "During the second half of 2014, the sales drop significantly under the average value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9048973",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = df.copy()\n",
    "tmp_df = tmp_df[tmp_df['year']==2014]\n",
    "tmp_df = tmp_df.groupby(tmp_df['month']).sum()\n",
    "\n",
    "plt.title('Promos done in 2014')\n",
    "sns.lineplot(data=tmp_df, x=tmp_df.index, y=tmp_df['promo'], palette='Blues', label='Promo1')\n",
    "sns.lineplot(data=tmp_df, x=tmp_df.index, y=tmp_df['promo2'], palette='Blues', label='Promo2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0675d4",
   "metadata": {},
   "source": [
    "The downwards trend of sales at the second half of 2014 until Christmas time seems to coincide with the decreasing number of promos during that period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799b1db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = df.groupby(df['timestamp']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7aaadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#freq = 7(weekly), 30(monthly), 365(yearly)\n",
    "weekly_decomp = seasonal_decompose(tmp_df['sales'], model='additive', freq=7)\n",
    "monthly_decomp = seasonal_decompose(tmp_df['sales'], model='additive', freq=30)\n",
    "yearly_decomp = seasonal_decompose(tmp_df['sales'], model='additive', freq=365)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows=3, ncols=1, figsize=(18,8))\n",
    "ax1.plot(weekly_decomp.trend)\n",
    "ax1.axhline(y = tmp_df['sales'].mean(), color = 'r', linestyle = '-', label='Sales Mean')\n",
    "ax1.set_title(\"Weekly Trend\")\n",
    "ax2.plot(monthly_decomp.trend)\n",
    "ax2.axhline(y = tmp_df['sales'].mean(), color = 'r', linestyle = '-', label='Sales Mean')\n",
    "ax2.set_title(\"Monthly Trend\")\n",
    "ax3.plot(yearly_decomp.trend)\n",
    "ax3.axhline(y = tmp_df['sales'].mean(), color = 'r', linestyle = '-', label='Sales Mean')\n",
    "ax3.set_title(\"Yearly Trend\")\n",
    "fig.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91d0169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot autocorrelation\n",
    "f, (ax1, ax2) = plt.subplots(2, figsize = (12, 6))\n",
    "plot_acf(tmp_df['sales'], lags = 50, ax=ax1)\n",
    "plot_pacf(tmp_df['sales'], lags = 50, ax=ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb089ea",
   "metadata": {},
   "source": [
    "Those plots are showing the correlation of the series with itself, lagged by x time units correlation of the series with itself, lagged by x time units.\n",
    "\n",
    "There is at two things common: non randomnes of the time series and high lag-1 (which will probably need a higher order of differencing d/D).\n",
    "\n",
    "There is a weekly trend with positives spikes at the 7(s), 14(2s), 21(3s) and 28(4s) lags.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d072c0ac",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2122889",
   "metadata": {},
   "source": [
    "In this section, varios categorical features will be either one-hot encoded(nominal feature) or label encoded (ordinal data). In addition, features regarding holiday and promo intervals will also be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dde7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e31449",
   "metadata": {},
   "source": [
    "First, the test data-set needs to be cleaned and features converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182b3705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing date into datetime object, inserting year, month, day and dayofyear columns\n",
    "df_test = df_test.assign(\n",
    "            timestamp = lambda x: pd.to_datetime(x['date']),\n",
    "            year = lambda x: x['timestamp'].dt.year,\n",
    "            month = lambda x: x['timestamp'].dt.month,\n",
    "            day = lambda x: x['timestamp'].dt.day,\n",
    "            dayofyear = lambda x: x['timestamp'].dt.dayofyear)\n",
    "df_test.drop(\"date\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95501d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for correct assignment of 'stateholiday' values\n",
    "print(df_test['stateholiday'].unique())\n",
    "print(df_test['stateholiday'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5a11f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for closed stores\n",
    "df_test[df_test[\"open\"].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9701054",
   "metadata": {},
   "source": [
    "All of these store have no information for 'open', although these days are not a holiday ('stateholiday =/= 1) and are not affected by the closure of schools. They should be open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0f9749",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['open'].fillna(1, inplace=True)\n",
    "df_test['open']= df_test['open'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557a6fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae904e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['is_train'] = 1\n",
    "df_test['is_train'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfea9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.columns)\n",
    "print('-----------------')\n",
    "print(df_test.columns)\n",
    "print('-----------------')\n",
    "print(df_store.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096e8d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46891fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d8e585",
   "metadata": {},
   "source": [
    "### Feature engineering from store features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38dba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_x = ['store', 'timestamp', 'dayofweek', 'open', 'promo', 'schoolholiday', 'stateholiday']\n",
    "features_y = ['saleslog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6547369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding categorical features\n",
    "df_model['stateholiday'] = LabelEncoder().fit_transform(df_model['stateholiday']) \n",
    "df_store['storetype'] = LabelEncoder().fit_transform(df_store['storetype'])\n",
    "df_store['assortment'] = LabelEncoder().fit_transform(df_store['assortment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d9d923",
   "metadata": {},
   "source": [
    "Promo interval feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d9ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting 'Promointerval' string into individual strings and get the month\n",
    "prom_interval = df_store['promointerval'].str.split(',').apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f82966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prom_interval.columns = prom_interval.columns.map(lambda x: str(x) + '_prominterval')\n",
    "df_store = df_store.join(prom_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19d5660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthToNum(value):\n",
    "    if(value=='Sept'):\n",
    "        value='Sep'\n",
    "    return list(calendar.month_abbr).index(value)\n",
    "#mapping month abbr to month number\n",
    "df_store['0_prominterval'] = df_store['0_prominterval'].map(lambda x: monthToNum(x) if str(x) != 'nan' else np.nan)\n",
    "df_store['1_prominterval'] = df_store['1_prominterval'].map(lambda x: monthToNum(x) if str(x) != 'nan' else np.nan)\n",
    "df_store['2_prominterval'] = df_store['2_prominterval'].map(lambda x: monthToNum(x) if str(x) != 'nan' else np.nan)\n",
    "df_store['3_prominterval'] = df_store['3_prominterval'].map(lambda x: monthToNum(x) if str(x) != 'nan' else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1757ac3",
   "metadata": {},
   "source": [
    "Promo feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695f5c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "promo = []\n",
    "for index, value in df_store[['promo2sinceweek', 'promo2sinceyear']].iterrows():\n",
    "    try:\n",
    "        year, week = int(value['promo2sinceyear']), int(value['promo2sinceweek'])\n",
    "        date = pd.to_datetime(\"{}-{}-01\".format(year, week), format='%Y%W')\n",
    "        promo.append(date)\n",
    "    except:\n",
    "        promo.append(np.nan)\n",
    "promo = pd.to_datetime(pd.Series(promo))\n",
    "promo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bde34c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store['promosince'] = promo #converted int to datetime\n",
    "df_store['promosince'] = df_store.promosince.dt.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5055a4ee",
   "metadata": {},
   "source": [
    "Competition feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad600f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_open = []\n",
    "for index, value in df_store[['competitionopensincemonth', 'competitionopensinceyear']].iterrows():\n",
    "    try:\n",
    "        year, month = int(value['competitionopensinceyear']), int(value['competitionopensincemonth'])\n",
    "        date = pd.to_datetime(\"{}-{}-01\".format(year, month), format='%Y-%m')\n",
    "        competition_open.append(date)\n",
    "    except:\n",
    "        competition_open.append(np.nan)\n",
    "competition_open = pd.Series(competition_open)\n",
    "competition_open.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f44376",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store['competitionopen'] = competition_open #converted int to datetime\n",
    "df_store['competitionopen'] = df_store['competitionopen'].dt.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46ea5ed",
   "metadata": {},
   "source": [
    "This concludes the feature engineering from df_store.\n",
    "The newly created features are put into store_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddc0209",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_features = ['store', 'storetype', 'assortment', 'competitiondistance', 'competitionopen', \n",
    "                  'promosince', '0_prominterval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca378ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.merge(df_model, df_store[store_features], how='left', on=['store'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4a6338",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1344af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put new features into feature-list\n",
    "features_x = list(set(features_x + store_features))\n",
    "\n",
    "for feature in features_x:\n",
    "    df_model[feature] = df_model[feature].fillna(-999) #out of range value for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12c7fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model['dateint'] = df_model.timestamp.dt.strftime('%Y%m%d').map(int) #mapping to Int\n",
    "df_model['competitionopen'] = df_model.competitionopen.map(int)\n",
    "df_model['promosince'] = df_model.promosince.map(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431471e9",
   "metadata": {},
   "source": [
    "### Feature engineering from df_train features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15058188",
   "metadata": {},
   "source": [
    "Holiday feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9ba794",
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays_next_week=[]\n",
    "holidays_next_week_index=[]\n",
    "for index, value in df_model.groupby(df_model['timestamp']).sum().iterrows():\n",
    "    start_range = index + datetime.timedelta(days=7)\n",
    "    end_range = index + datetime.timedelta(days=15)\n",
    "    school_holidays = sum((df_model.groupby(df['timestamp']).sum()[start_range:end_range]).schoolholiday)\n",
    "    state_holidays = sum((df_model.groupby(df['timestamp']).sum()[start_range:end_range]).stateholiday)\n",
    "    holidays_next_week.append(school_holidays+state_holidays)\n",
    "    holidays_next_week_index.append(index)\n",
    "    \n",
    "holidays_next_week = pd.Series(holidays_next_week)\n",
    "holidays_next_week.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc829de",
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays_this_week=[]\n",
    "index_list = []\n",
    "for index, value in df_model.groupby(df_model['timestamp']).sum().iterrows():\n",
    "    start_range = index \n",
    "    end_range = index + datetime.timedelta(days=7)\n",
    "    school_holidays = sum((df_model.groupby(df['timestamp']).sum()[start_range:end_range]).schoolholiday)\n",
    "    state_holidays = sum((df_model.groupby(df['timestamp']).sum()[start_range:end_range]).stateholiday)\n",
    "    holidays_this_week.append(school_holidays+state_holidays)\n",
    "    index_list.append(index)\n",
    "    \n",
    "holidays_this_week = pd.Series(holidays_this_week)\n",
    "holidays_this_week.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146fd272",
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays_last_week=[]\n",
    "holidays_last_week_index=[]\n",
    "for index, value in df_model.groupby(df_model['timestamp']).sum().iterrows():\n",
    "    start_range = index - datetime.timedelta(days=7)\n",
    "    end_range = index + datetime.timedelta(days=1)\n",
    "    school_holidays = sum((df_model.groupby(df['timestamp']).sum()[start_range:end_range]).schoolholiday)\n",
    "    state_holidays = sum((df_model.groupby(df['timestamp']).sum()[start_range:end_range]).stateholiday)\n",
    "    holidays_last_week.append(school_holidays+state_holidays)\n",
    "    holidays_last_week_index.append(index)\n",
    "    \n",
    "holidays_last_week = pd.Series(holidays_next_week)\n",
    "holidays_last_week.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa060e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame({'holidaysnextweek':holidays_next_week, 'timestamp': holidays_next_week_index})\n",
    "df_model = pd.merge(df_model, temp_df, on=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1909dbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame({'holidaysthisweek':holidays_this_week, 'timestamp': index_list})\n",
    "df_model = pd.merge(df_model, temp_df, on=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408c7225",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame({'holidayslastweek':holidays_last_week, 'timestamp': holidays_last_week_index})\n",
    "df_model = pd.merge(df_model, temp_df, on=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec461f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays_features = ['holidaysnextweek', 'holidaysthisweek', 'holidayslastweek']\n",
    "\n",
    "features_x = list(set(features_x + holidays_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0b48b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_model.shape)\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7dfb9d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b1a76eef85ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_model' is not defined"
     ]
    }
   ],
   "source": [
    "print(df_model.columns)\n",
    "print(features_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff05b7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_x = ['open', 'store', 'storetype', 'holidayslastweek', '0_prominterval', 'stateholiday', 'assortment', 'dateint', 'holidaysthisweek',\n",
    "              'holidaysnextweek', 'promo', 'promosince', 'dayofweek', 'competitionopen', 'schoolholiday', 'competitiondistance']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc20506",
   "metadata": {},
   "source": [
    "# Predictive modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31544bf1",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b60190",
   "metadata": {},
   "source": [
    "For XGBoost and the RMSPE evaluation, no 0 values are permitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b05ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = df_model.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3995a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.sales = df_model.sales.apply(lambda x: np.nan if x == 0 else x)\n",
    "df_model.loc[df_model['is_train'] == 1, 'saleslog'] = np.log(1+df_model.loc[df_model['is_train'] == 1]['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e58831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "data = df_model.loc[(df_model['is_train'] == 1)]\n",
    "x_train, x_test, y_train, y_test = train_test_split(data[features_x], \n",
    "                                                    data[features_y], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e97240",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a471ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dtest = xgb.DMatrix(x_test, y_test)\n",
    "\n",
    "num_round = 1000\n",
    "evallist = [(dtrain, 'train'), (dtest, 'test')]\n",
    "\n",
    "param = {'max_depth': 9,\n",
    "         'eta': 0.01,\n",
    "         'subsample': 0.75,\n",
    "         'colsample_bytree': 0.6, \n",
    "         'objective': 'reg:squarederror',}\n",
    "\n",
    "plst = list(param.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84f25bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToWeight(y):\n",
    "    w = np.zeros(y.shape, dtype=float)\n",
    "    ind = y != 0\n",
    "    w[ind] = 1./(y[ind]**2)\n",
    "    return w\n",
    "\n",
    "def rmspe(yhat, y):\n",
    "    w = ToWeight(y)\n",
    "    rmspe = np.sqrt(np.mean( w * (y - yhat)**2 ))\n",
    "    return rmspe\n",
    "\n",
    "def rmspe_xg(yhat, y):\n",
    "    y = y.get_label()\n",
    "    y = np.exp(y) - 1\n",
    "    yhat = np.exp(yhat) - 1\n",
    "    w = ToWeight(y)\n",
    "    rmspe = np.sqrt(np.mean(w * (y - yhat)**2))\n",
    "    return \"rmspe\", rmspe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ed345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modto_csvxgb.train(plst, dtrain, num_round, evallist,\n",
    "                  feval=rmspe_xg, verbose_eval=25, early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99e6343",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print Feature Importance\n",
    "plt.figure(figsize=(18,8))\n",
    "from xgboost import plot_importance\n",
    "plot_importance(model)\n",
    "plt.show()\n",
    "plt.savefig('xgboost_feature_importance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347036d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframes on disk\n",
    "df.to_csv('dataframe_raw', index=False)\n",
    "df_model.to_csv('dataframe_raw_model', index=False)\n",
    "data.to_csv('dataframe_modeldata', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b2268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model using pickle\n",
    "import pickle\n",
    "filename = 'model_xgboost_01.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e93dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a submission dataframe to test RMSPE for unseen test-data (test.csv)\n",
    "submit = df_model.loc[df_model['is_train'] == 0]\n",
    "dsubmit = xgb.DMatrix(submit[features_x])\n",
    "predictions = model.predict(dsubmit)\n",
    "\n",
    "df_predictions = submit['id'].reset_index()\n",
    "df_predictions['Id'] = df_predictions['id'].astype('int')\n",
    "df_predictions['Sales'] = (np.exp(predictions) - 1) * 0.985 #Scale Back\n",
    "\n",
    "df_predictions.sort_values('Id', inplace=True)\n",
    "df_predictions[['Id', 'Sales']].to_csv('submit_xgboost_01.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
